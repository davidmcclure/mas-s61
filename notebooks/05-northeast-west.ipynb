{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = Word2Vec.load('../data/northeast.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = Word2Vec.load('../data/west.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_vocab = set(m1.wv.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_vocab = set(m2.wv.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set.intersection(m1_vocab, m2_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_m = np.stack([m1[t] for t in vocab])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_m = np.stack([m2[t] for t in vocab])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "basevecs = m1_m - m1_m.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "othervecs = m2_m - m2_m.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = othervecs.T.dot(basevecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, _, v = np.linalg.svd(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ortho = u.dot(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2f = othervecs.dot(ortho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i, token in enumerate(vocab):\n",
    "    if not token.startswith('#') and token.endswith('cy'):\n",
    "        d = cosine(m1_m[i], m2f[i])\n",
    "        data.append((token, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns=('token', 'distance'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>quincy</td>\n",
       "      <td>0.459943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>prophecy</td>\n",
       "      <td>0.400942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>pharmacy</td>\n",
       "      <td>0.365218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>clancy</td>\n",
       "      <td>0.257566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@lvnancy</td>\n",
       "      <td>0.239420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>tracy</td>\n",
       "      <td>0.238310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.233603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>stacy</td>\n",
       "      <td>0.230605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cy</td>\n",
       "      <td>0.228833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>nancy</td>\n",
       "      <td>0.225771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>juicy</td>\n",
       "      <td>0.193395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>frequency</td>\n",
       "      <td>0.184086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>residency</td>\n",
       "      <td>0.168422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>lucy</td>\n",
       "      <td>0.155048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>macy</td>\n",
       "      <td>0.149548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bankruptcy</td>\n",
       "      <td>0.148497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>icy</td>\n",
       "      <td>0.141396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>urgency</td>\n",
       "      <td>0.137518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>currency</td>\n",
       "      <td>0.130121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>tendency</td>\n",
       "      <td>0.128231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>literacy</td>\n",
       "      <td>0.120883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>emergency</td>\n",
       "      <td>0.106212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>privacy</td>\n",
       "      <td>0.101852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>confederacy</td>\n",
       "      <td>0.101067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>spicy</td>\n",
       "      <td>0.099797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>efficiency</td>\n",
       "      <td>0.098123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>conspiracy</td>\n",
       "      <td>0.096392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>idiocy</td>\n",
       "      <td>0.095698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>consistency</td>\n",
       "      <td>0.094375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>legitimacy</td>\n",
       "      <td>0.092829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>decency</td>\n",
       "      <td>0.092747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>advocacy</td>\n",
       "      <td>0.089071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>transparency</td>\n",
       "      <td>0.087890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>mercy</td>\n",
       "      <td>0.087850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>pregnancy</td>\n",
       "      <td>0.087427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>diplomacy</td>\n",
       "      <td>0.085234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>supremacy</td>\n",
       "      <td>0.079603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>fancy</td>\n",
       "      <td>0.079469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>agency</td>\n",
       "      <td>0.069406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>legacy</td>\n",
       "      <td>0.056474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>policy</td>\n",
       "      <td>0.045057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>democracy</td>\n",
       "      <td>0.044591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>presidency</td>\n",
       "      <td>0.037229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           token  distance\n",
       "34        quincy  0.459943\n",
       "33      prophecy  0.400942\n",
       "28      pharmacy  0.365218\n",
       "5         clancy  0.257566\n",
       "0       @lvnancy  0.239420\n",
       "40         tracy  0.238310\n",
       "1       accuracy  0.233603\n",
       "37         stacy  0.230605\n",
       "10            cy  0.228833\n",
       "27         nancy  0.225771\n",
       "20         juicy  0.193395\n",
       "17     frequency  0.184086\n",
       "35     residency  0.168422\n",
       "24          lucy  0.155048\n",
       "25          macy  0.149548\n",
       "4     bankruptcy  0.148497\n",
       "18           icy  0.141396\n",
       "42       urgency  0.137518\n",
       "9       currency  0.130121\n",
       "39      tendency  0.128231\n",
       "23      literacy  0.120883\n",
       "15     emergency  0.106212\n",
       "32       privacy  0.101852\n",
       "6    confederacy  0.101067\n",
       "36         spicy  0.099797\n",
       "14    efficiency  0.098123\n",
       "8     conspiracy  0.096392\n",
       "19        idiocy  0.095698\n",
       "7    consistency  0.094375\n",
       "22    legitimacy  0.092829\n",
       "11       decency  0.092747\n",
       "2       advocacy  0.089071\n",
       "41  transparency  0.087890\n",
       "26         mercy  0.087850\n",
       "30     pregnancy  0.087427\n",
       "13     diplomacy  0.085234\n",
       "38     supremacy  0.079603\n",
       "16         fancy  0.079469\n",
       "3         agency  0.069406\n",
       "21        legacy  0.056474\n",
       "29        policy  0.045057\n",
       "12     democracy  0.044591\n",
       "31    presidency  0.037229"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values('distance', ascending=False).head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(token):\n",
    "    for t, _ in m1.most_similar(token, topn=20):\n",
    "        print(t)\n",
    "    print('\\n')\n",
    "    for t, _ in m2.most_similar(token, topn=20):\n",
    "        print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freedoms\n",
      "patriotism\n",
      "tyranny\n",
      "equality\n",
      "democracy\n",
      "acceptance\n",
      "oppression\n",
      "prosperity\n",
      "intolerance\n",
      "liberation\n",
      "liberty\n",
      "independence\n",
      "rights\n",
      "fascism\n",
      "unity\n",
      "religion\n",
      "morality\n",
      "constitution\n",
      "values\n",
      "hatred\n",
      "\n",
      "\n",
      "freedoms\n",
      "#freedom\n",
      "liberty\n",
      "sovereignty\n",
      "equality\n",
      "patriotism\n",
      "liberation\n",
      "tyranny\n",
      "democracy\n",
      "rights\n",
      "intolerance\n",
      "independence\n",
      "liberties\n",
      "acceptance\n",
      "oppression\n",
      "constitution\n",
      "morality\n",
      "compassion\n",
      "unity\n",
      "civility\n"
     ]
    }
   ],
   "source": [
    "compare('freedom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
